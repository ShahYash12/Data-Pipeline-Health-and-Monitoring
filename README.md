
# ğŸ“Š Data Pipeline Monitoring for Sales Ops

**Internship Project â€“ Future Investment**  
**Tools**: SQL, Python, Tableau  
**Duration**: [Insert Duration]  
**Role**: Data Analyst Intern

---

## ğŸ“ Overview

This project was built to ensure robust monitoring and alerting for sales operations data pipelines at Future Investment. During the internship, I identified critical issues related to pipeline latency, data inconsistency, and lack of visibility for stakeholders. To address these, I developed a comprehensive monitoring system using SQL for audits, Python for automation and alerts, and Tableau for live operational insights.

---

## ğŸ¯ Goals

- Audit existing data pipelines and improve reporting consistency.
- Automate health and freshness checks to preempt failures.
- Visualize real-time metrics for enhanced operational decision-making.

---

## ğŸ§° Tools & Technologies

| Tool     | Purpose                                  |
|----------|------------------------------------------|
| **SQL**  | Query data freshness, failure logs, inconsistencies |
| **Python** | Automate health checks and alerts     |
| **Tableau** | Visual dashboard for operational insights |

---

## ğŸ› ï¸ What I Built

### ğŸ” 1. SQL Pipeline Auditing

- Wrote SQL scripts to identify failed ETL jobs and stale pipeline data.
- Improved reporting reliability by **35%** through targeted audits.

**Key SQL Scripts:**
- `Freshness Check`: Detects outdated pipeline outputs  
```sql
SELECT pipeline_name, MAX(last_run_time) AS last_run
FROM etl_job_status
GROUP BY pipeline_name
HAVING MAX(last_run_time) < CURRENT_TIMESTAMP - INTERVAL '6 HOURS';
```

- `Failed ETL Jobs`: Retrieves most recent failed jobs  
```sql
SELECT *
FROM etl_job_status
WHERE status = 'FAILED'
ORDER BY last_run_time DESC;
```

---

### ğŸ 2. Python-Based Health Checks & Alert System

- Automated hourly checks for pipeline failures and data freshness.
- Implemented email-based alerts using `smtplib` for escalations.
- Reduced stakeholder escalations and metric delays by **40%**.

**Modules Implemented:**
- `data_freshness_checker.py`: Checks for stale records  
- `error_log_parser.py`: Extracts failed ETL jobs  
- `email_alerts.py`: Sends automated notifications  
- `utils/logger.py`: Custom logger for monitoring logs  

---

### ğŸ“Š 3. Tableau Dashboards

- Designed interactive dashboards to visualize:
  - Pipeline health status (Success, Failed, Stale)
  - Daily job counts and error trends
  - Time-based filters for historical view
- Used in weekly Sales Ops sync meetings to improve transparency and reduce investigation time.

---

## ğŸ“ˆ Impact

| Metric                          | Result       |
|----------------------------------|--------------|
| Reporting reliability improved   | **+35%**     |
| Metric delay & escalations cut   | **âˆ’40%**     |
| Ops insight visibility (Tableau) | **Real-time**|

---

## ğŸ”„ Folder Structure

```
data-pipeline-monitoring/
â”œâ”€â”€ README.md
â”œâ”€â”€ sql/
â”‚   â”œâ”€â”€ Freshness Check.sql.txt
â”‚   â””â”€â”€ Failed_ETL_Jobs.sql.txt
â”œâ”€â”€ python/
â”‚   â”œâ”€â”€ data_freshness_checker.py
â”‚   â”œâ”€â”€ error_log_parser.py
â”‚   â”œâ”€â”€ email_alerts.py
â”‚   â””â”€â”€ utils/
â”‚       â””â”€â”€ logger.py
â”œâ”€â”€ data/
â”‚   â””â”€â”€ [Sample CSVs, pipeline logs]
â”œâ”€â”€ tableau/
â”‚   â””â”€â”€ dashboard_screenshots/
â”‚       â””â”€â”€ pipeline_monitoring_dashboard.png
```

---

## âœ… Future Enhancements

- Integrate with **Slack** for real-time alerts.
- Add **anomaly detection** using statistical thresholds.
- Build **API hooks** for dynamic health dashboards.

---

## ğŸ‘¤ Author

**Yash Shah**  
[LinkedIn](https://www.linkedin.com/in/yashshah033/) | [GitHub](https://github.com/ShahYash12) | [Portfolio](https://yash-shah-portfolio.notion.site)

---

> ğŸ“Œ _This project represents real-world experience in proactive monitoring, operational analytics, and cross-functional collaboration using modern data tools._
